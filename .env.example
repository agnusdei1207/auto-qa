# Auto-QA System Configuration - Enhanced v2.0

# Ports
WEB_PORT=3000              # Web UI
BRAIN_PORT=9000            # Brain API
EXECUTOR_PORT=9001         # Executor API
DB_PORT=15432              # Database

# Ollama LLM
# Use internal Docker service: http://ollama:11434
# Use external Ollama: http://host.docker.internal:11434 or actual IP
OLLAMA_API_URL=http://ollama:11434
OLLAMA_PORT=11434

# LLM Model
LLM_MODEL=gemma3:1b        # Or: llama3:8b, mistral, etc.

# Database Config
DB_HOST=database
DB_NAME=qa_results
DB_USER=qa_user
DB_PASS=qa_password

# File Persistence
SCREENSHOT_DIR=/tmp/screenshots
PROGRESS_DIR=/tmp/progress
ERROR_LOG_DIR=/tmp/error_logs

# Execution Modes
DEFAULT_HEADFUL=false       # Enable headful by default
ENABLE_PARALLEL=true        # Enable parallel execution
MAX_PARALLEL_AGENTS=4       # Max parallel agents

# Git Auto-Commit
ENABLE_GIT_AUTO_COMMIT=true  # Auto-commit test results to git
GIT_REPO_PATH=.             # Path to git repository
GIT_BRANCH=main             # Branch to push to

# Resource Monitoring
MAX_MEMORY_MB=4096         # Max memory usage per session (MB)
MAX_CPU_PERCENT=80          # Max CPU usage threshold (%)
MONITOR_INTERVAL=5          # Resource monitoring interval (seconds)
